{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": 122,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "r [[[-0.11617039]\n",
                        "  [ 2.2125063 ]]]\n",
                        "jax log_wfi dumb -1.0731523 with shape ()\n",
                        "jax log_wfi smart -2.7578166 with shape ()\n",
                        "jax grad [[ 0.4608419 -0.4608419]] with shape (1, 2)\n"
                    ]
                }
            ],
            "source": [
                "import jax\n",
                "import jax.numpy as jnp\n",
                "from jax import vmap\n",
                "from jax import random\n",
                "import numpy as np\n",
                "class testClass:\n",
                "    def __init__(self, N, dim):\n",
                "        self._N = N\n",
                "        self._dim = dim\n",
                "        self.la = jax.numpy.linalg\n",
                "\n",
                "    def log_wfi_dumb(self, r, params): # dumb because JW does not need to be (N, N), it can be (N*(N-1)//2, )\n",
                "        epsilon = 1e-6  # Small epsilon value\n",
                "        r_cpy = r.reshape(-1, self._N, self._dim)\n",
                "        r_diff = r_cpy[:, None, :, :] - r_cpy[:, :, None, :]\n",
                "        r_dist = self.la.norm(r_diff + epsilon, axis=-1)  # Add epsilon to avoid nan\n",
                "\n",
                "        rij = jnp.triu(r_dist, k=1)\n",
                "\n",
                "        x = jnp.einsum('nij,ij->n', rij, params['JW_dumb'])\n",
                "        \n",
                "        return x.squeeze(-1)\n",
                "    \n",
                "    def log_wfi_smart(self, r, params):\n",
                "        epsilon = 1e-6  # Small epsilon value for stability\n",
                "        r_cpy = r.reshape(-1, self._N, self._dim)\n",
                "        r_diff = r_cpy[:, None, :, :] - r_cpy[:, :, None, :]\n",
                "        r_dist = self.la.norm(r_diff + epsilon, axis=-1)  # Add epsilon to avoid nan\n",
                "        \n",
                "        rij = jnp.triu(r_dist, k=1)\n",
                "        \n",
                "        # Generate indices for the upper triangular matrix excluding diagonal\n",
                "        triu_indices = jnp.triu_indices(self._N, k=1)\n",
                "        k = triu_indices[0] * (self._N - 1) - triu_indices[0] * (triu_indices[0] + 1) // 2 + triu_indices[1] - triu_indices[0] - 1\n",
                "        \n",
                "        # Use these indices to select the corresponding elements from the JW_smart vector\n",
                "        JW_smart = params['JW_smart'][k]\n",
                "        \n",
                "        # Perform the element-wise multiplication and sum\n",
                "        x = jnp.einsum('nij,i->n', rij, JW_smart)\n",
                "        \n",
                "        return x.squeeze(-1)\n",
                "\n",
                "    \n",
                "    # jax grad\n",
                "    def grad_log_wfi_dumb(self, r, params):\n",
                "        return vmap(jax.grad(self.log_wfi_dumb, argnums=0), in_axes=(0, None))(r, params)\n",
                "\n",
                "\n",
                "    def grad_log_wfi_smart(self, r, params):\n",
                "        return vmap(jax.grad(self.log_wfi_smart, argnums=0), in_axes=(0, None))(r, params)\n",
                "        \n",
                "        \n",
                "    \n",
                "# initialize r with shape (nbatch, particles * dim)\n",
                "nbatch = 1\n",
                "N = 2\n",
                "dim = 1\n",
                "key = random.PRNGKey(1)\n",
                "r = random.normal(key, (nbatch, N * dim))\n",
                "\n",
                "print(\"r\", r.reshape(-1, N, dim))\n",
                "# initialize params\n",
                "\n",
                "params_dumb = {'JW_dumb': random.normal(key, (N, N))}\n",
                "params_smart = {'JW_smart': random.normal(key, (N * (N-1) // 2, ))}\n",
                "\n",
                "# grad\n",
                "# instantiate the class\n",
                "your_class = testClass(N, dim)\n",
                "your_class.log_wfi_dumb(r, params_dumb)\n",
                "\n",
                "#print the forward pass\n",
                "log_wfi = your_class.log_wfi_dumb(r, params_dumb)\n",
                "print(\"jax log_wfi dumb\", log_wfi, \"with shape\", log_wfi.shape)\n",
                "log_wfi = your_class.log_wfi_smart(r, params_smart)\n",
                "print(\"jax log_wfi smart\", log_wfi, \"with shape\", log_wfi.shape)\n",
                "\n",
                "grad_log_wfi = your_class.grad_log_wfi_dumb(r, params_dumb)\n",
                "print(\"jax grad\", grad_log_wfi, \"with shape\", grad_log_wfi.shape)\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 144,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "particle 0 [[0.25483576]]\n",
                        "particle 1 [[-0.71301476]]\n",
                        "=====\n",
                        "particle 0 [[0.25483576]]\n",
                        "particle 1 [[-0.71301476]]\n"
                    ]
                }
            ],
            "source": [
                "nbatch = 1\n",
                "N = 2\n",
                "dim = 1\n",
                "r = np.random.randn(nbatch, N * dim)\n",
                "#r = np.random.randn(N * dim,)\n",
                "# mode 1\n",
                "r_reshaped = r.reshape(-1, N, dim)\n",
                "for i in range(N):\n",
                "    # access particle i\n",
                "    print(\"particle\", i, r_reshaped[:, i, :])\n",
                "print(\"=====\")\n",
                "# mode 2\n",
                "# instead of reshaping, use strided access\n",
                "for i in range(0, N*dim, dim):\n",
                "    print(\"particle\", i//dim, r[..., i:i+dim])"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 46,
            "metadata": {},
            "outputs": [
                {
                    "ename": "ValueError",
                    "evalue": "Dimension mismatch between 'vals' and 'dim'.",
                    "output_type": "error",
                    "traceback": [
                        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
                        "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
                        "Cell \u001b[0;32mIn[46], line 28\u001b[0m\n\u001b[1;32m     24\u001b[0m         hermite_product \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m=\u001b[39m hermite_poly\n\u001b[1;32m     26\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m hermite_product\n\u001b[0;32m---> 28\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mhermite\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m)\n",
                        "Cell \u001b[0;32mIn[46], line 18\u001b[0m, in \u001b[0;36mhermite\u001b[0;34m(vals, deg, dim)\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid input types for vals, deg, or dim.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(vals) \u001b[38;5;241m!=\u001b[39m dim:\n\u001b[0;32m---> 18\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDimension mismatch between \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvals\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m and \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdim\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     20\u001b[0m \u001b[38;5;66;03m# Compute the product of Hermite polynomials across the given dimensions\u001b[39;00m\n\u001b[1;32m     21\u001b[0m hermite_product \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
                        "\u001b[0;31mValueError\u001b[0m: Dimension mismatch between 'vals' and 'dim'."
                    ]
                }
            ],
            "source": [
                "import numpy.polynomial.hermite as P\n",
                "def hermite(vals, deg, dim):\n",
                "    \"\"\"\n",
                "    Compute the product of Hermite polynomials for the given values, degree, and dimension.\n",
                "\n",
                "    Parameters:\n",
                "    - vals: Array-like of values for which to compute the Hermite polynomial product.\n",
                "    - deg: The degree of the Hermite polynomial.\n",
                "    - dim: The dimension, indicating how many values and subsequent polynomials to consider.\n",
                "\n",
                "    Returns:\n",
                "    - The product of Hermite polynomials for the given inputs.\n",
                "    \"\"\"\n",
                "    # Error handling for input parameters\n",
                "    if not isinstance(vals, list) or not isinstance(deg, int) or not isinstance(dim, int):\n",
                "        raise ValueError(\"Invalid input types for vals, deg, or dim.\")\n",
                "    if len(vals) != dim:\n",
                "        raise ValueError(\"Dimension mismatch between 'vals' and 'dim'.\")\n",
                "\n",
                "    # Compute the product of Hermite polynomials across the given dimensions\n",
                "    hermite_product = 1\n",
                "    for val in vals:\n",
                "        hermite_poly = P.Hermite([0] * deg + [1])(val)\n",
                "        hermite_product *= hermite_poly\n",
                "\n",
                "    return hermite_product\n",
                "\n",
                "print(hermite([2, 2], 1, dim=2))\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "array([[0, 0, 0],\n",
                            "       [1, 0, 0],\n",
                            "       [0, 1, 0],\n",
                            "       [0, 0, 1],\n",
                            "       [2, 0, 0]])"
                        ]
                    },
                    "execution_count": 4,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "def generate_degrees(nparticles, dim):\n",
                "    max_comb = nparticles // 2\n",
                "    combinations = [[0] * dim]\n",
                "    seen = {tuple(combinations[0])}\n",
                "    \n",
                "    while len(combinations) < max_comb:\n",
                "        new_combinations = []\n",
                "        for comb in combinations:\n",
                "            for i in range(dim):\n",
                "                # Try incrementing each dimension by 1\n",
                "                new_comb = comb.copy()\n",
                "                new_comb[i] += 1\n",
                "                new_comb_tuple = tuple(new_comb)\n",
                "                if new_comb_tuple not in seen:\n",
                "                    seen.add(new_comb_tuple)\n",
                "                    new_combinations.append(new_comb)\n",
                "                    if len(seen) == max_comb:\n",
                "                        return np.array(combinations + new_combinations)\n",
                "        combinations += new_combinations\n",
                "    \n",
                "    return np.array(combinations)\n",
                "dim = 3\n",
                "nparticles = 10\n",
                "combinations_v2 = generate_degrees(nparticles, dim)\n",
                "combinations_v2\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 33,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "/var/folders/gg/pt9rjjws0_b60pgd3qk984140000gn/T/ipykernel_84528/3763078808.py:70: DeprecationWarning: `np.math` is a deprecated alias for the standard library `math` module (Deprecated Numpy 1.25). Replace usages of `np.math` with `math`\n",
                        "  slater_fact = np.log(np.sqrt(np.math.factorial(nparticles)))\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "print(P.Hermite([0] * 0 + [1])(-0.4519834816455841))\n",
                        "print(P.Hermite([0] * 0 + [1])(-0.5464293956756592))\n",
                        "print(P.Hermite([0] * 0 + [1])(-0.35051533579826355))\n",
                        "print(P.Hermite([0] * 0 + [1])(0.44277459383010864))\n",
                        "print(P.Hermite([0] * 1 + [1])(-0.4519834816455841))\n",
                        "print(P.Hermite([0] * 0 + [1])(-0.5464293956756592))\n",
                        "print(P.Hermite([0] * 1 + [1])(-0.35051533579826355))\n",
                        "print(P.Hermite([0] * 0 + [1])(0.44277459383010864))\n",
                        "print(P.Hermite([0] * 0 + [1])(-0.4519834816455841))\n",
                        "print(P.Hermite([0] * 1 + [1])(-0.5464293956756592))\n",
                        "print(P.Hermite([0] * 0 + [1])(-0.35051533579826355))\n",
                        "print(P.Hermite([0] * 1 + [1])(0.44277459383010864))\n",
                        "print(P.Hermite([0] * 2 + [1])(-0.4519834816455841))\n",
                        "print(P.Hermite([0] * 0 + [1])(-0.5464293956756592))\n",
                        "print(P.Hermite([0] * 2 + [1])(-0.35051533579826355))\n",
                        "print(P.Hermite([0] * 0 + [1])(0.44277459383010864))\n",
                        "print(P.Hermite([0] * 1 + [1])(-0.4519834816455841))\n",
                        "print(P.Hermite([0] * 1 + [1])(-0.5464293956756592))\n",
                        "print(P.Hermite([0] * 1 + [1])(-0.35051533579826355))\n",
                        "print(P.Hermite([0] * 1 + [1])(0.44277459383010864))\n",
                        "print(P.Hermite([0] * 0 + [1])(-1.9026196002960205))\n",
                        "print(P.Hermite([0] * 0 + [1])(1.866502046585083))\n",
                        "print(P.Hermite([0] * 0 + [1])(-0.3804941177368164))\n",
                        "print(P.Hermite([0] * 0 + [1])(-1.365081787109375))\n",
                        "print(P.Hermite([0] * 1 + [1])(-1.9026196002960205))\n",
                        "print(P.Hermite([0] * 0 + [1])(1.866502046585083))\n",
                        "print(P.Hermite([0] * 1 + [1])(-0.3804941177368164))\n",
                        "print(P.Hermite([0] * 0 + [1])(-1.365081787109375))\n",
                        "print(P.Hermite([0] * 0 + [1])(-1.9026196002960205))\n",
                        "print(P.Hermite([0] * 1 + [1])(1.866502046585083))\n",
                        "print(P.Hermite([0] * 0 + [1])(-0.3804941177368164))\n",
                        "print(P.Hermite([0] * 1 + [1])(-1.365081787109375))\n",
                        "print(P.Hermite([0] * 2 + [1])(-1.9026196002960205))\n",
                        "print(P.Hermite([0] * 0 + [1])(1.866502046585083))\n",
                        "print(P.Hermite([0] * 2 + [1])(-0.3804941177368164))\n",
                        "print(P.Hermite([0] * 0 + [1])(-1.365081787109375))\n",
                        "print(P.Hermite([0] * 1 + [1])(-1.9026196002960205))\n",
                        "print(P.Hermite([0] * 1 + [1])(1.866502046585083))\n",
                        "print(P.Hermite([0] * 1 + [1])(-0.3804941177368164))\n",
                        "print(P.Hermite([0] * 1 + [1])(-1.365081787109375))\n",
                        "print(P.Hermite([0] * 0 + [1])(0.4130476415157318))\n",
                        "print(P.Hermite([0] * 0 + [1])(-0.07904303073883057))\n",
                        "print(P.Hermite([0] * 0 + [1])(-0.1926344335079193))\n",
                        "print(P.Hermite([0] * 0 + [1])(0.5415079593658447))\n",
                        "print(P.Hermite([0] * 1 + [1])(0.4130476415157318))\n",
                        "print(P.Hermite([0] * 0 + [1])(-0.07904303073883057))\n",
                        "print(P.Hermite([0] * 1 + [1])(-0.1926344335079193))\n",
                        "print(P.Hermite([0] * 0 + [1])(0.5415079593658447))\n",
                        "print(P.Hermite([0] * 0 + [1])(0.4130476415157318))\n",
                        "print(P.Hermite([0] * 1 + [1])(-0.07904303073883057))\n",
                        "print(P.Hermite([0] * 0 + [1])(-0.1926344335079193))\n",
                        "print(P.Hermite([0] * 1 + [1])(0.5415079593658447))\n",
                        "print(P.Hermite([0] * 2 + [1])(0.4130476415157318))\n",
                        "print(P.Hermite([0] * 0 + [1])(-0.07904303073883057))\n",
                        "print(P.Hermite([0] * 2 + [1])(-0.1926344335079193))\n",
                        "print(P.Hermite([0] * 0 + [1])(0.5415079593658447))\n",
                        "print(P.Hermite([0] * 1 + [1])(0.4130476415157318))\n",
                        "print(P.Hermite([0] * 1 + [1])(-0.07904303073883057))\n",
                        "print(P.Hermite([0] * 1 + [1])(-0.1926344335079193))\n",
                        "print(P.Hermite([0] * 1 + [1])(0.5415079593658447))\n",
                        "print(P.Hermite([0] * 0 + [1])(-1.4673446416854858))\n",
                        "print(P.Hermite([0] * 0 + [1])(-0.5516906976699829))\n",
                        "print(P.Hermite([0] * 0 + [1])(-1.2325048446655273))\n",
                        "print(P.Hermite([0] * 0 + [1])(-0.7028056383132935))\n",
                        "print(P.Hermite([0] * 1 + [1])(-1.4673446416854858))\n",
                        "print(P.Hermite([0] * 0 + [1])(-0.5516906976699829))\n",
                        "print(P.Hermite([0] * 1 + [1])(-1.2325048446655273))\n",
                        "print(P.Hermite([0] * 0 + [1])(-0.7028056383132935))\n",
                        "print(P.Hermite([0] * 0 + [1])(-1.4673446416854858))\n",
                        "print(P.Hermite([0] * 1 + [1])(-0.5516906976699829))\n",
                        "print(P.Hermite([0] * 0 + [1])(-1.2325048446655273))\n",
                        "print(P.Hermite([0] * 1 + [1])(-0.7028056383132935))\n",
                        "print(P.Hermite([0] * 2 + [1])(-1.4673446416854858))\n",
                        "print(P.Hermite([0] * 0 + [1])(-0.5516906976699829))\n",
                        "print(P.Hermite([0] * 2 + [1])(-1.2325048446655273))\n",
                        "print(P.Hermite([0] * 0 + [1])(-0.7028056383132935))\n",
                        "print(P.Hermite([0] * 1 + [1])(-1.4673446416854858))\n",
                        "print(P.Hermite([0] * 1 + [1])(-0.5516906976699829))\n",
                        "print(P.Hermite([0] * 1 + [1])(-1.2325048446655273))\n",
                        "print(P.Hermite([0] * 1 + [1])(-0.7028056383132935))\n",
                        "print(P.Hermite([0] * 0 + [1])(-0.9570719003677368))\n",
                        "print(P.Hermite([0] * 0 + [1])(1.093062162399292))\n",
                        "print(P.Hermite([0] * 0 + [1])(-0.7791742086410522))\n",
                        "print(P.Hermite([0] * 0 + [1])(-0.6818073987960815))\n",
                        "print(P.Hermite([0] * 1 + [1])(-0.9570719003677368))\n",
                        "print(P.Hermite([0] * 0 + [1])(1.093062162399292))\n",
                        "print(P.Hermite([0] * 1 + [1])(-0.7791742086410522))\n",
                        "print(P.Hermite([0] * 0 + [1])(-0.6818073987960815))\n",
                        "print(P.Hermite([0] * 0 + [1])(-0.9570719003677368))\n",
                        "print(P.Hermite([0] * 1 + [1])(1.093062162399292))\n",
                        "print(P.Hermite([0] * 0 + [1])(-0.7791742086410522))\n",
                        "print(P.Hermite([0] * 1 + [1])(-0.6818073987960815))\n",
                        "print(P.Hermite([0] * 2 + [1])(-0.9570719003677368))\n",
                        "print(P.Hermite([0] * 0 + [1])(1.093062162399292))\n",
                        "print(P.Hermite([0] * 2 + [1])(-0.7791742086410522))\n",
                        "print(P.Hermite([0] * 0 + [1])(-0.6818073987960815))\n",
                        "print(P.Hermite([0] * 1 + [1])(-0.9570719003677368))\n",
                        "print(P.Hermite([0] * 1 + [1])(1.093062162399292))\n",
                        "print(P.Hermite([0] * 1 + [1])(-0.7791742086410522))\n",
                        "print(P.Hermite([0] * 1 + [1])(-0.6818073987960815))\n"
                    ]
                },
                {
                    "data": {
                        "text/plain": [
                            "Array([-3.7761033], dtype=float32)"
                        ]
                    },
                    "execution_count": 33,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "import jax.numpy as jnp\n",
                "import jax\n",
                "from numpy import polynomial as P\n",
                "import numpy as np\n",
                "nparticles = 10\n",
                "dim = 2\n",
                "\n",
                "\n",
                "\n",
                "def hermite(r, degs):\n",
                "    \"\"\"\n",
                "    Compute the product of Hermite polynomials for the given values, degree, and dimension.\n",
                "\n",
                "    Parameters:\n",
                "    - vals: Array-like of values for which to compute the Hermite polynomial product. It should be of shape (nbatch, dim)\n",
                "    - degs: The degrees of the Hermite polynomials.\n",
                "    - dim: The dimension, indicating how many values and subsequent polynomials to consider.\n",
                "\n",
                "    Returns:\n",
                "    - The product of Hermite polynomials for the given inputs.\n",
                "\n",
                "    #TODO: move this to a helper function\n",
                "    \"\"\"\n",
                "    # Error handling for input parameters\n",
                "    #if not isinstance(vals, list) or not isinstance(deg, int) or not isinstance(self._dim, int):\n",
                "    #    raise ValueError(\"Invalid input types for vals, deg, or dim.\")\n",
                "    #if len(vals) != dim:\n",
                "    #    raise ValueError(\"Dimension mismatch between 'vals' and 'dim'.\")\n",
                "\n",
                "\n",
                "    # Compute the product of Hermite polynomials across the given dimensions\n",
                "    hermite_product = 1\n",
                "    for batch in range(r.shape[0]):\n",
                "        #cartesian of r[batch] and degs\n",
                "        \n",
                "        for i in range(len(degs)):\n",
                "            deg = degs[i]\n",
                "            r_ = r[batch][i]\n",
                "            #print(f\"print(P.Hermite([0] * {deg} + [1])({r_}))\")\n",
                "            hermite_poly = P.Hermite([0] * int(deg) + [1])(r_)\n",
                "            hermite_product *= hermite_poly\n",
                "\n",
                "\n",
                "    return hermite_product\n",
                "\n",
                "\n",
                "def log_slater(r):\n",
                "    \"\"\"\n",
                "    Decomposed spin Slater determinant in log domain.\n",
                "    ln psi = ln det (D(up)) + ln det (D(down))\n",
                "    In our ground state, half of the particles are spin up and half are spin down.\n",
                "    We will also add the 1/sqrt(N!) normalization factor here.\n",
                "\n",
                "    D = |phi_1(r_1) phi_2(r_1) ... phi_n(r_1)| \n",
                "        |phi_1(r_2) phi_2(r_2) ... phi_n(r_2)| \n",
                "        |   ...         ...          ...     | \n",
                "        |phi_1(r_n) phi_2(r_n) ... phi_n(r_n)| \n",
                "\n",
                "    where phi_i is the i-th single particle wavefunction, in our case it is a hermite polynomial.\n",
                "    \"\"\"\n",
                "    A = nparticles // 2\n",
                "    r = r.reshape(-1, nparticles, dim)\n",
                "    r_up = r[:, : A, :]\n",
                "    r_down = r[:, A :, :]\n",
                "    slater_fact = np.log(np.sqrt(np.math.factorial(nparticles)))\n",
                "\n",
                "    # Compute the Slater determinant for the spin up particles\n",
                "    D_up = jnp.zeros((r.shape[0], A, A))\n",
                "    D_down = jnp.zeros((r.shape[0], A, A))\n",
                "\n",
                "    degree_combs = generate_degrees(nparticles, dim)\n",
                "\n",
                "    for part in range(A):\n",
                "        for j in range(A):\n",
                "            degrees = degree_combs[j] \n",
                "            \n",
                "            #print(\"====hermite\", hermite(r_up[:, part, :], degrees))\n",
                "            \n",
                "            D_up = D_up.at[:, part, j].set(hermite(r_up[:, part, :], degrees))\n",
                "            D_down = D_down.at[:, part, j].set(hermite(r_down[:, part, :], degrees))\n",
                "\n",
                "    # Compute the Slater determinant for the spin down particles\n",
                "    log_slater_up = jnp.linalg.slogdet(D_up)[0]\n",
                "    log_slater_down = jnp.linalg.slogdet(D_down)[0]\n",
                "\n",
                "    return log_slater_up + log_slater_down - 0.5 * slater_fact # we can precompute this. The minus sign is because we are computing the log of the inverse of the factorial\n",
                "\n",
                "\n",
                "r = jnp.array(np.random.randn(1, nparticles * dim))\n",
                "log_slater(r)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 93,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "1/wf * grad_wf [[-2.0443762e-04  3.5990626e-04 -7.4185060e-05]\n",
                        " [-1.9279356e-05 -5.8702957e-05  4.9267084e-05]\n",
                        " [ 1.7390294e-04  5.0164206e-05 -2.6005344e-04]]\n",
                        "grad ln  [[-2.0443763e-04  3.5990626e-04 -7.4185060e-05]\n",
                        " [-1.9279356e-05 -5.8702961e-05  4.9267088e-05]\n",
                        " [ 1.7390294e-04  5.0164210e-05 -2.6005344e-04]]\n",
                        "\n",
                        " grad ln wf == 1/wf * grad_wf True\n",
                        "\n",
                        "  1/det * grad det [[12654.426   3515.1284  9140.335 ]\n",
                        " [88889.74   65342.605  72046.914 ]\n",
                        " [13230.24   11376.392  18732.555 ]]\n",
                        "==== det 2.5276656e-13\n",
                        "grad ln det [[12654.425  3515.128  9140.333]\n",
                        " [88889.734 65342.6   72046.91 ]\n",
                        " [13230.239 11376.391 18732.553]]\n",
                        "\n",
                        " grad ln det == 1/det * grad_det False\n"
                    ]
                }
            ],
            "source": [
                "dim = 3\n",
                "def det(r):\n",
                "    det_r = jnp.linalg.det(r)\n",
                "    return det_r\n",
                "\n",
                "def log_det(r):\n",
                "    log_det_r = jnp.linalg.slogdet(r)[1]\n",
                "    return log_det_r\n",
                "\n",
                "def wf(r):\n",
                "    return jnp.exp(-jnp.linalg.norm(r)**2)\n",
                "\n",
                "def log_wf(r):\n",
                "    return -jnp.linalg.norm(r)**2\n",
                "\n",
                "r = jnp.array(np.random.randn(dim, dim)) \n",
                "\n",
                "grad_det = jax.grad(det)(r)\n",
                "grad_wf = jax.grad(wf)(r)\n",
                "\n",
                "\n",
                "print(\"1/wf * grad_wf\", grad_wf / wf(r))\n",
                "\n",
                "print(\"grad ln \", jax.grad(log_wf)(r))\n",
                "\n",
                "print(\"\\n grad ln wf == 1/wf * grad_wf\", (abs(jax.grad(log_wf)(r) - grad_wf / wf(r)) < 0.001).all())\n",
                "\n",
                "print(\"\\n  1/det * grad det\", grad_det / det(r))\n",
                "\n",
                "print(\"==== det\", det(r))\n",
                "print(\"grad ln det\", jax.grad(log_det)(r))\n",
                "\n",
                "\n",
                "\n",
                "print(\"\\n grad ln det == 1/det * grad_det\", (abs(jax.grad(log_det)(r) - grad_det / det(r)) < 0.001).all())\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 98,
            "metadata": {},
            "outputs": [],
            "source": [
                "nparticles = 6\n",
                "dim = 2\n",
                "\n",
                "pade_aij = jnp.zeros((nparticles, nparticles))\n",
                "for i in range(nparticles):\n",
                "    for j in range(i+1, nparticles):\n",
                "        # first N//2 particles are spin up, the rest are spin down\n",
                "        # there is a more efficient way to do this for sure\n",
                "        if i < nparticles // 2 and j < nparticles // 2:\n",
                "            pade_aij = pade_aij.at[i, j].set(1 / (dim + 1))\n",
                "        elif i >= nparticles // 2 and j >= nparticles // 2:\n",
                "            pade_aij = pade_aij.at[i, j].set(1 / (dim + 1))\n",
                "        else: \n",
                "            pade_aij = pade_aij.at[i, j].set(1 / (dim - 1))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 99,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "Array([[0.        , 0.33333334, 0.33333334, 1.        , 1.        ,\n",
                            "        1.        ],\n",
                            "       [0.        , 0.        , 0.33333334, 1.        , 1.        ,\n",
                            "        1.        ],\n",
                            "       [0.        , 0.        , 0.        , 1.        , 1.        ,\n",
                            "        1.        ],\n",
                            "       [0.        , 0.        , 0.        , 0.        , 0.33333334,\n",
                            "        0.33333334],\n",
                            "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
                            "        0.33333334],\n",
                            "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
                            "        0.        ]], dtype=float32)"
                        ]
                    },
                    "execution_count": 99,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "pade_aij"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "array([[[[ True,  True,  True],\n",
                            "         [ True,  True,  True],\n",
                            "         [ True,  True,  True]],\n",
                            "\n",
                            "        [[ True,  True,  True],\n",
                            "         [ True,  True,  True],\n",
                            "         [ True,  True,  True]],\n",
                            "\n",
                            "        [[ True,  True,  True],\n",
                            "         [ True,  True,  True],\n",
                            "         [ True,  True,  True]]],\n",
                            "\n",
                            "\n",
                            "       [[[ True,  True,  True],\n",
                            "         [ True,  True,  True],\n",
                            "         [ True,  True,  True]],\n",
                            "\n",
                            "        [[ True,  True,  True],\n",
                            "         [ True,  True,  True],\n",
                            "         [ True,  True,  True]],\n",
                            "\n",
                            "        [[ True,  True,  True],\n",
                            "         [ True,  True,  True],\n",
                            "         [ True,  True,  True]]],\n",
                            "\n",
                            "\n",
                            "       [[[ True,  True,  True],\n",
                            "         [ True,  True,  True],\n",
                            "         [ True,  True,  True]],\n",
                            "\n",
                            "        [[ True,  True,  True],\n",
                            "         [ True,  True,  True],\n",
                            "         [ True,  True,  True]],\n",
                            "\n",
                            "        [[ True,  True,  True],\n",
                            "         [ True,  True,  True],\n",
                            "         [ True,  True,  True]]]])"
                        ]
                    },
                    "execution_count": 5,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "import numpy as np\n",
                "\n",
                "A = np.random.randn(3, 3)\n",
                "B = np.random.randn(3, 3)\n",
                "\n",
                "# outer\n",
                "C = np.outer(A, B).reshape(3,3,3,3,)\n",
                "\n",
                "D = np.einsum('ij,kl->ijkl', A, B)\n",
                "\n",
                "\n",
                "\n",
                "C - D < 1e-6"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "WARNING: LapJAX:  When wrapping `jax` modules `collect_profile.py`, got ImportError:\n",
                        "    This script requires `tensorboard_plugin_profile` to be installed.\n",
                        "WARNING: LapJAX:  This won't affect functions of other modules.\n"
                    ]
                }
            ],
            "source": [
                "import lapjax"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "[[2. 2. 2. ... 2. 2. 2.]\n",
                        " [2. 2. 2. ... 2. 2. 2.]\n",
                        " [2. 2. 2. ... 2. 2. 2.]\n",
                        " ...\n",
                        " [2. 2. 2. ... 2. 2. 2.]\n",
                        " [2. 2. 2. ... 2. 2. 2.]\n",
                        " [2. 2. 2. ... 2. 2. 2.]]\n",
                        "lapjax time 0.29260730743408203\n",
                        "[[2. 2. 2. ... 2. 2. 2.]\n",
                        " [2. 2. 2. ... 2. 2. 2.]\n",
                        " [2. 2. 2. ... 2. 2. 2.]\n",
                        " ...\n",
                        " [2. 2. 2. ... 2. 2. 2.]\n",
                        " [2. 2. 2. ... 2. 2. 2.]\n",
                        " [2. 2. 2. ... 2. 2. 2.]]\n",
                        "hess time 14.127750873565674\n"
                    ]
                }
            ],
            "source": [
                "# import jax.numpy as jnp\n",
                "# from jax import vmap\n",
                "import lapjax.numpy as jnp\n",
                "from lapjax import vmap\n",
                "import jax \n",
                "\n",
                "import numpy as np\n",
                "import time \n",
                "from functools import partial\n",
                "\n",
                "\n",
                "def f(x, params):\n",
                "    return params*x**2 \n",
                "\n",
                "from lapjax import LapTuple, TupType\n",
                "\n",
                "# input_x is the input of f(x)\n",
                "\n",
                "#@partial(jax.jit)\n",
                "def lap_of_f(x, params):\n",
                "  input_x = LapTuple(x, is_input = True)\n",
                "  output = f(input_x, params)\n",
                "  return output.lap\n",
                "\n",
                "def lap_of_f_hess(x, params):\n",
                "  hessian_wf = vmap(jax.hessian(f), in_axes=(0, None))\n",
                "  trace_hessian = vmap(jnp.trace)\n",
                "  return trace_hessian(hessian_wf(x, params))\n",
                "\n",
                "\n",
                "\n",
                "arr = np.random.randn(2000,100)\n",
                "params = 1.0\n",
                "start = time.time()\n",
                "print(lap_of_f(arr, params))\n",
                "print(\"lapjax time\", time.time() - start)\n",
                "\n",
                "arr = np.random.randn(2000,100)\n",
                "start = time.time()\n",
                "print(lap_of_f_hess(arr, params))\n",
                "print(\"hess time\", time.time() - start)\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 11,
            "metadata": {},
            "outputs": [],
            "source": [
                "# CASE2: a Slater-Determinants like wave functions\n",
                "# In this case, we could leverage the derivative sparsity to\n",
                "# achieve over a magnitude speed-up.\n",
                "\n",
                "# construct input params\n",
                "key = jax.random.PRNGKey(42)\n",
                "\n",
                "n_elec = 16 # number of electrons\n",
                "input_dim = 3 # the dimension of electron position\n",
                "hidden_dim = 256\n",
                "hidden_layer = 2\n",
                "layer_dims = [input_dim,] + [hidden_dim,] * hidden_layer + [n_elec,]\n",
                "\n",
                "def init_params(key):\n",
                "    params = []\n",
                "    left_dim = input_dim\n",
                "    for right_dim in layer_dims:\n",
                "        key, subkey = jax.random.split(key)\n",
                "        params.append(jax.random.normal(subkey, (left_dim,right_dim)) * 0.1)\n",
                "        left_dim = right_dim\n",
                "    return params\n",
                "\n",
                "# construct the wave functions. \n",
                "def slater_determinants(x, params):\n",
                "\n",
                "    # x.shape = (n_elec * input_dim,)\n",
                "    x = x.reshape(n_elec, input_dim)\n",
                "    for param in params:\n",
                "        # Each electron is processed by the same MLP function\n",
                "        x = jnp.matmul(x, param)\n",
                "        x = jnp.tanh(x)\n",
                "\n",
                "    x = x + jnp.eye(x.shape[0])\n",
                "\n",
                "    \n",
                "\n",
                "    _, lnpsi = jnp.linalg.slogdet(x)\n",
                "    return lnpsi\n",
                "\n",
                "key, subkey = jax.random.split(key)\n",
                "params_sd = init_params(key)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 12,
            "metadata": {},
            "outputs": [],
            "source": [
                "def get_kinetic_function_orig(func):\n",
                "    def kinetic(data):\n",
                "        grad = jax.grad(func)(data)\n",
                "        print(\"grad\", grad.shape)\n",
                "        hess = jax.hessian(func)(data)\n",
                "        return -0.5 * (jnp.trace(hess) + jnp.sum(grad ** 2))\n",
                "        \n",
                "    return kinetic\n",
                "\n",
                "def get_kinetic_function_lapjax(func):\n",
                "    from lapjax import LapTuple\n",
                "    def kinetic(data):\n",
                "        input_laptuple = LapTuple(data, is_input=True)\n",
                "        output_laptuple = func(input_laptuple)\n",
                "        grad = output_laptuple.grad\n",
                "        print(\"grad\", grad.shape)\n",
                "        lap = output_laptuple.lap\n",
                "\n",
                "        # A Laptupe stores both gradient and laplacian information,\n",
                "        # so we do not need to compute gradient again.\n",
                "        return -0.5 * lap - 0.5 * jnp.sum(grad**2)\n",
                "\n",
                "    return kinetic\n",
                "\n",
                "# get kinetic function\n",
                "ke_original = get_kinetic_function_orig(lambda x: slater_determinants(x, params_sd))\n",
                "ke_lapjax = get_kinetic_function_lapjax(lambda x: slater_determinants(x, params_sd))\n",
                "\n",
                "vmap_ke_orignal = jax.jit(jax.vmap(ke_original))\n",
                "vmap_ke_lapjax = jax.jit(jax.vmap(ke_lapjax))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 13,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "grad (48,)\n",
                        "grad (48,)\n",
                        "7.1525574e-07\n"
                    ]
                }
            ],
            "source": [
                "# CASE2: precision test\n",
                "batch_size = 128\n",
                "\n",
                "key, subkey = jax.random.split(key)\n",
                "data = jax.random.normal(subkey,(batch_size, input_dim*n_elec))\n",
                "\n",
                "orig_results = vmap_ke_orignal(data)\n",
                "lapjax_results = vmap_ke_lapjax(data)\n",
                "\n",
                "# the maxium difference is a standard float32 numerical error\n",
                "print(jnp.max(jnp.abs(orig_results-lapjax_results)))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 15,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "time of hessian-trace: 17.55272603034973\n",
                        "time of forward laplacian: 1.7136318683624268\n"
                    ]
                }
            ],
            "source": [
                "import time\n",
                "def compute_time(vfunc, key, batch_size, input_dim, iterations=100):\n",
                "    key, subkey = jax.random.split(key)\n",
                "    data_pool = jax.random.normal(subkey,(iterations*2, batch_size, input_dim))\n",
                "    \n",
                "    data_pool1, data_pool2 = jnp.split(data_pool, 2)\n",
                "\n",
                "    # warm up to avoid the cache problem\n",
                "    for data in data_pool1:\n",
                "        val = vfunc(data)\n",
                "\n",
                "    start_time = time.time()\n",
                "    for data in data_pool2:\n",
                "        val = vfunc(data)\n",
                "    end_time = time.time()\n",
                "    return val, end_time - start_time\n",
                "\n",
                "\n",
                "val, duration = compute_time(vmap_ke_orignal, \n",
                "                             key, batch_size, input_dim * n_elec)\n",
                "print('time of hessian-trace:', duration)\n",
                "\n",
                "val, duration = compute_time(vmap_ke_lapjax, \n",
                "                             key, batch_size, input_dim * n_elec)\n",
                "# forward laplacian is roughly 2 times faster than the original method\n",
                "print('time of forward laplacian:', duration)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 19,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "0.0017466545104980469\n",
                        "0.0014252662658691406\n"
                    ]
                }
            ],
            "source": [
                "from functools import partial\n",
                "\n",
                "import jax\n",
                "import jax.numpy as jnp\n",
                "from jax.experimental import jet\n",
                "# jet.fact = lambda n: jax.lax.prod(range(1, n + 1))\n",
                "\n",
                "def f(ws, wo, x):\n",
                "    for w in ws:\n",
                "        x = jax.lax.exp(x @ w)\n",
                "    return jnp.reshape(x @ wo, ())\n",
                "\n",
                "@jax.jit\n",
                "@partial(jax.vmap, in_axes=(None, None, 0))\n",
                "def laplacian_1(ws, wo, x):\n",
                "    fun = partial(f, ws, wo)\n",
                "    @jax.vmap\n",
                "    def hvv(v):\n",
                "        return jet.jet(fun, (x,), ((v, jnp.zeros_like(x)),))[1][1]\n",
                "    return jnp.sum(hvv(jnp.eye(x.shape[0], dtype=x.dtype)))\n",
                "\n",
                "@jax.jit\n",
                "@partial(jax.vmap, in_axes=(None, None, 0))\n",
                "def laplacian_3(ws, wo, x):\n",
                "    fun = partial(f, ws, wo)\n",
                "    return jnp.trace(jax.hessian(fun)(x))\n",
                "\n",
                "def timer(f):\n",
                "    from time import time\n",
                "    f() # compile\n",
                "    t = time()\n",
                "    for _ in range(3):\n",
                "        f()\n",
                "    print((time() - t) / 3)\n",
                "\n",
                "d = 16\n",
                "ws = [jnp.zeros((d, d)) for _ in range(5)]\n",
                "wo = jnp.zeros((d, 1))\n",
                "x = jnp.zeros((512, d))\n",
                "\n",
                "timer(lambda : jax.block_until_ready(laplacian_1(ws, wo, x)))\n",
                "timer(lambda : jax.block_until_ready(laplacian_3(ws, wo, x)))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 31,
            "metadata": {},
            "outputs": [
                {
                    "ename": "IndexError",
                    "evalue": "list index out of range",
                    "output_type": "error",
                    "traceback": [
                        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
                        "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
                        "Cell \u001b[0;32mIn[31], line 11\u001b[0m\n\u001b[1;32m      7\u001b[0m container \u001b[38;5;241m=\u001b[39m [[positions] \u001b[38;5;241m*\u001b[39m batch_size]\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m#print(\"container_dim\", container)\u001b[39;00m\n\u001b[0;32m---> 11\u001b[0m \u001b[38;5;28mtype\u001b[39m(\u001b[43mcontainer\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m)\n",
                        "\u001b[0;31mIndexError\u001b[0m: list index out of range"
                    ]
                }
            ],
            "source": [
                "import jax.numpy as jnp\n",
                "\n",
                "positions = jnp.array([1,2,3])\n",
                "\n",
                "# tst 1\n",
                "batch_size = 3\n",
                "container = [[positions] * batch_size]\n",
                "\n",
                "#print(\"container_dim\", container)\n",
                "\n",
                "type(container[1])\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 25,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "array([[1, 2, 3],\n",
                            "       [1, 2, 3],\n",
                            "       [1, 2, 3]], dtype=int32)"
                        ]
                    },
                    "execution_count": 25,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "container"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## checking stuff"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 32,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "Array([[  30.997993  , -101.03757   ,  203.5024    , ...,  137.86655   ,\n",
                            "          94.08075   ,  221.06895   ],\n",
                            "       [ 226.67355   ,  168.71967   ,   48.394302  , ..., -176.88821   ,\n",
                            "         -40.23911   ,  386.17163   ],\n",
                            "       [-177.22252   ,    6.9170856 , -192.93011   , ...,    0.93268967,\n",
                            "           6.961529  ,  121.673874  ],\n",
                            "       ...,\n",
                            "       [-239.57462   , -279.90347   ,    5.686722  , ...,  158.27287   ,\n",
                            "         137.40155   ,  -78.64044   ],\n",
                            "       [  69.14392   ,   27.83804   ,  -85.63251   , ...,   -4.4442024 ,\n",
                            "          27.685966  ,  -22.886019  ],\n",
                            "       [-111.65703   ,   51.84831   ,  -98.04352   , ...,   40.530052  ,\n",
                            "         276.60132   ,  -75.43979   ]], dtype=float32)"
                        ]
                    },
                    "execution_count": 32,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "import jax.numpy as jnp\n",
                "import numpy as np\n",
                "import time \n",
                "\n",
                "\n",
                "\n",
                "\n",
                "x_np = np.random.randn(1000, 1000)\n",
                "y_np = np.random.randn(1000, 1000)\n",
                "\n",
                "\n",
                "def dot_and_stuff(x, y):\n",
                "    return jnp.dot(x, y) + 100*x + 100*y\n",
                "\n",
                "\n",
                "start = time.time()\n",
                "dot_and_stuff(x_np, y_np)\n",
                "    \n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": []
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3.10.12 ('.venv': poetry)",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.12"
        },
        "orig_nbformat": 4,
        "vscode": {
            "interpreter": {
                "hash": "540899a6d5f72233f45842563b6aafa756d796888aa192a1b7fe41908bbe83fa"
            }
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
